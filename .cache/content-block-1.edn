{:block-id "1", :code "from optim_hunter.datasets import get_dataset_friedman_2\nfrom optim_hunter.utils import slice_dataset, prepare_prompt, prepare_prompt_from_tokens, pad_numeric_tokens\nfrom optim_hunter.llama_model import load_llama_model\n\nllama_model = load_llama_model()\n\nseq_len = 3  # Number of examples to show the model\nx_train, y_train, x_test, y_test = get_dataset_friedman_2()\nx_train, y_train, x_test, y_test = slice_dataset(\n    x_train, y_train, x_test, y_test, seq_len\n)\nprompt = prepare_prompt(x_train, y_train, x_test)\n\nx_train_tokens, y_train_tokens, x_test_tokens = pad_numeric_tokens(llama_model, x_train, y_train, x_test)\ntokenized_prompt = prepare_prompt_from_tokens(llama_model, x_train_tokens, y_train_tokens, x_test_tokens)\ndecoded_prompt = llama_model.to_string(tokenized_prompt[0])\n\nprint(decoded_prompt)", :output "<pre class=\"code-output\">Loaded pretrained model meta-llama/Meta-Llama-3-8B-Instruct into HookedTransformer\n<|begin_of_text|>The task is to provide your best estimate for \"Output\". Please provide that and only that, without any additional text.\n\n\n\n\nFeature 0: 39.680\nFeature 1: 1005.89\nFeature 2: 0.420\nFeature 3: 7.850\nOutput: 423.530\n\nFeature 0: 1.40\nFeature 1: 508.520\nFeature 2: 0.620\nFeature 3: 10.490\nOutput: 313.650\n\nFeature 0: 90.850\nFeature 1: 1144.0\nFeature 2: 0.020\nFeature 3: 10.290\nOutput: 92.640\n\nFeature 0: 66.340\nFeature 1: 1141.28\nFeature 2: 0.110\nFeature 3: 10.490\nOutput: \n</pre>\n", :timestamp 1738755581208}