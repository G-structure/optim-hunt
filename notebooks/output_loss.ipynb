{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Int, Float\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import (\n",
    "    utils,\n",
    "    HookedTransformer,\n",
    "    HookedTransformerConfig,\n",
    "    FactoredMatrix,\n",
    "    ActivationCache,\n",
    ")\n",
    "import circuitsvis as cv\n",
    "\n",
    "from optim_hunter.plotly_utils import imshow, hist, plot_comp_scores, plot_logit_attribution, plot_loss_difference, line\n",
    "from optim_hunter.utils import prepare_prompt, slice_dataset, prepare_prompt_from_tokens, pad_numeric_tokens\n",
    "from optim_hunter.sklearn_regressors import linear_regression, knn_regression, random_forest, baseline_average, baseline_last, baseline_random\n",
    "from optim_hunter.datasets import get_dataset_friedman_2\n",
    "from optim_hunter.data_model import create_comparison_data\n",
    "from optim_hunter.model_utils import get_numerical_tokens, generate_linreg_tokens, run_and_cache_model_linreg_tokens_batched, run_and_cache_model_linreg_tokens\n",
    "from optim_hunter.llama_model import load_llama_model\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Saves computation time, since we don't need it for the contents of this notebook\n",
    "t.set_grad_enabled(False)\n",
    "\n",
    "#device = t.device(\"cuda:0,1\" if t.cuda.is_available() else \"cpu\")\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "# device = t.device(\"cpu\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_llama_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9630716",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset_friedman_2\n",
    "seq_len = 25\n",
    "random_int = 1\n",
    "def get_prompt(seq_len, random_int, print_prompt=True):\n",
    "    x_train, y_train, x_test, y_test = dataset(random_int)\n",
    "    x_train, y_train, x_test, y_test = slice_dataset(\n",
    "        x_train, y_train, x_test, y_test, seq_len\n",
    "    )\n",
    "    x_train_tokens, y_train_tokens, x_test_tokens = pad_numeric_tokens(\n",
    "                    model, x_train, y_train, x_test\n",
    "                )\n",
    "    tokenized_prompt = prepare_prompt_from_tokens(\n",
    "        model, x_train_tokens, y_train_tokens, x_test_tokens, prepend_bos=True, prepend_inst=True\n",
    "    )\n",
    "\n",
    "    prompt = model.to_string(tokenized_prompt[0])\n",
    "    if print_prompt: print(prompt)\n",
    "    return tokenized_prompt\n",
    "tokenized_prompt = get_prompt(seq_len, random_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa4793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982a52c",
   "metadata": {},
   "source": [
    "What is the model's loss for the first numerical token following \"Output:\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linreg_output_loss(tokenized_prompt):\n",
    "    input_tokens = tokenized_prompt.to(model.cfg.device)\n",
    "    logits = model(input_tokens)\n",
    "    log_probs = model.loss_fn(logits, input_tokens, per_token=True)\n",
    "    loss_by_position = einops.reduce(log_probs, \"batch position -> position\", \"mean\")\n",
    "\n",
    "\n",
    "    # Get string tokens for the full sequence\n",
    "    str_tokens = model.to_str_tokens(input_tokens[0])\n",
    "\n",
    "    # Find indices where \"Output:\" appears, starting from position 24\n",
    "    output_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Output\"]\n",
    "\n",
    "    # Get just the first number token after each \"Output:\"\n",
    "    output_losses = []\n",
    "    output_tokens = []\n",
    "    for idx in output_indices:\n",
    "        # Skip the \":\" and \" \" tokens by starting 3 positions after \"Output\"\n",
    "        current_pos = idx + 3\n",
    "        if current_pos < len(str_tokens) - 1:\n",
    "            output_losses.append(loss_by_position[current_pos].item())\n",
    "            output_tokens.append(str_tokens[current_pos])\n",
    "\n",
    "    return output_losses, output_tokens\n",
    "\n",
    "output_losses, output_tokens = plot_linreg_output_loss(tokenized_prompt)\n",
    "\n",
    "# Create figure with just the first number token\n",
    "fig = px.line(\n",
    "    output_losses,\n",
    "    labels={\"x\": \"Token Position\", \"y\": \"Loss\"},\n",
    "    title=\"Loss for First Output Number Token\"\n",
    ")\n",
    "\n",
    "# Update x-axis to show the actual tokens\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        ticktext = output_tokens,\n",
    "        tickvals = list(range(len(output_tokens))),\n",
    "        tickangle = 45\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcb9ee",
   "metadata": {},
   "source": [
    "Do the same thing only using 25 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 25 \n",
    "random_int = 1\n",
    "tokenized_prompt = get_prompt(seq_len, random_int, print_prompt=False)\n",
    "output_losses, output_tokens = plot_linreg_output_loss(tokenized_prompt)\n",
    "\n",
    "# Create figure with just the first number token\n",
    "fig = px.line(\n",
    "    output_losses,\n",
    "    labels={\"x\": \"Token Position\", \"y\": \"Loss\"},\n",
    "    title=\"Loss for First Output Number Token\"\n",
    ")\n",
    "\n",
    "# Update x-axis to show the actual tokens\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        ticktext = output_tokens,\n",
    "        tickvals = list(range(len(output_tokens))),\n",
    "        tickangle = 45\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3bb0d",
   "metadata": {},
   "source": [
    "Remove the outlilers to see if the loss is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 51\n",
    "random_int = 1\n",
    "tokenized_prompt = get_prompt(seq_len, random_int, print_prompt=False)\n",
    "output_losses, output_tokens = plot_linreg_output_loss(tokenized_prompt)\n",
    "\n",
    "# Remove outliers using more aggressive IQR method\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers(data, tokens, iqr_multiplier=0.5):\n",
    "    data = np.array(data)\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    \n",
    "    mask = (data >= lower_bound) & (data <= upper_bound)\n",
    "    return data[mask].tolist(), [t for i, t in enumerate(tokens) if mask[i]]\n",
    "\n",
    "# Filter out outliers\n",
    "filtered_losses, filtered_tokens = remove_outliers(output_losses, output_tokens)\n",
    "\n",
    "# Create figure with filtered data\n",
    "fig = px.line(\n",
    "    filtered_losses,\n",
    "    labels={\"x\": \"Token Position\", \"y\": \"Loss\"},\n",
    "    title=\"Loss for First Output Number Token (Outliers Removed)\"\n",
    ")\n",
    "\n",
    "# Update x-axis to show the actual tokens\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        ticktext = filtered_tokens,\n",
    "        tickvals = list(range(len(filtered_tokens))),\n",
    "        tickangle = 45\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead975e",
   "metadata": {},
   "source": [
    "Confirm that all first numerical tokens positions are the same for Output and Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ab145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output_token_positions(model, dataset, seq_len, num_seeds=5):\n",
    "    positions = []\n",
    "    for seed in range(num_seeds):\n",
    "        tokenized_prompt = get_prompt(seq_len, seed, print_prompt=False)\n",
    "        input_tokens = tokenized_prompt.to(model.cfg.device)\n",
    "        \n",
    "        # Get string tokens for the full sequence\n",
    "        str_tokens = model.to_str_tokens(input_tokens[0])\n",
    "        \n",
    "        # Find indices where \"Output:\" appears, starting from position 24\n",
    "        output_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Output\"]\n",
    "        \n",
    "        # Get positions of first number token after each \"Output:\"\n",
    "        output_positions = []\n",
    "        for idx in output_indices:\n",
    "            # Skip the \":\" and \" \" tokens by starting 3 positions after \"Output\"\n",
    "            current_pos = idx + 3\n",
    "            if current_pos < len(str_tokens) - 1:\n",
    "                output_positions.append(current_pos)\n",
    "        \n",
    "        positions.append(output_positions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nPositions of first number token after 'Output:' for each seed:\")\n",
    "    for seed, pos in enumerate(positions):\n",
    "        print(f\"Seed {seed}: {pos}\")\n",
    "    \n",
    "    # Check if all position lists are identical\n",
    "    all_same = all(pos == positions[0] for pos in positions[1:])\n",
    "    print(f\"\\nAll positions consistent across seeds: {all_same}\")\n",
    "    \n",
    "    return positions\n",
    "\n",
    "# Test with different sequence lengths\n",
    "seq_lens = [25, 50]\n",
    "for seq_len in seq_lens:\n",
    "    print(f\"\\nTesting with sequence length: {seq_len}\")\n",
    "    positions = check_output_token_positions(model, dataset, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_token_positions_multi(model, dataset, seq_len, num_seeds=5, print=\"true\"):\n",
    "    output_positions = []\n",
    "    feature_positions = []\n",
    "    \n",
    "    for seed in range(num_seeds):\n",
    "        tokenized_prompt = get_prompt(seq_len, seed, print_prompt=False)\n",
    "        input_tokens = tokenized_prompt.to(model.cfg.device)\n",
    "        \n",
    "        # Get string tokens for the full sequence\n",
    "        str_tokens = model.to_str_tokens(input_tokens[0])\n",
    "        \n",
    "        # Find indices where \"Output:\" and \"Features:\" appear\n",
    "        output_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Output\"]\n",
    "        feature_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Feature\"]\n",
    "        \n",
    "        # Get positions of first number token after each marker\n",
    "        seed_output_positions = []\n",
    "        for idx in output_indices:\n",
    "            current_pos = idx + 3  # Skip \"Output: \"\n",
    "            if current_pos < len(str_tokens) - 1:\n",
    "                seed_output_positions.append(current_pos)\n",
    "        \n",
    "        seed_feature_positions = []\n",
    "        for idx in feature_indices:\n",
    "            current_pos = idx + 5  # Skip \"Features n: \"\n",
    "            if current_pos < len(str_tokens) - 1:\n",
    "                seed_feature_positions.append(current_pos)\n",
    "        \n",
    "        output_positions.append(seed_output_positions)\n",
    "        feature_positions.append(seed_feature_positions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nPositions of first number token after 'Output:' for each seed:\")\n",
    "    for seed, pos in enumerate(output_positions):\n",
    "        print(f\"Seed {seed}: {pos}\")\n",
    "        \n",
    "    print(\"\\nPositions of first number token after 'Feature:' for each seed:\")\n",
    "    for seed, pos in enumerate(feature_positions):\n",
    "        print(f\"Seed {seed}: {pos}\")\n",
    "    \n",
    "    # Check if all position lists are identical\n",
    "    outputs_same = all(pos == output_positions[0] for pos in output_positions[1:])\n",
    "    features_same = all(pos == feature_positions[0] for pos in feature_positions[1:])\n",
    "    \n",
    "    print(f\"\\nAll Output positions consistent across seeds: {outputs_same}\")\n",
    "    print(f\"All Feature positions consistent across seeds: {features_same}\")\n",
    "    \n",
    "    # Print example tokens at these positions for first seed\n",
    "    print(\"\\nExample tokens at these positions (first seed):\")\n",
    "    str_tokens = model.to_str_tokens(get_prompt(seq_len, 0, print_prompt=False)[0])\n",
    "    print(\"After Output:\", [str_tokens[pos] for pos in output_positions[0]])\n",
    "    print(\"After Features:\", [str_tokens[pos] for pos in feature_positions[0]])\n",
    "    \n",
    "    return output_positions, feature_positions\n",
    "\n",
    "# Test with different sequence lengths\n",
    "seq_lens = [25, 50]\n",
    "for seq_len in seq_lens:\n",
    "    print(f\"\\nTesting with sequence length: {seq_len}\")\n",
    "    output_pos, feature_pos = check_token_positions_multi(model, dataset, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset_friedman_2\n",
    "\n",
    "def check_token_positions(model, dataset, seq_len, seed=0, print_info=True):\n",
    "    \"\"\"\n",
    "    Check token positions for a single sequence length and seed.\n",
    "    \n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        dataset: The dataset being used\n",
    "        seq_len: Sequence length to test\n",
    "        seed: Random seed (default: 0)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lists of output and feature positions\n",
    "    \"\"\"\n",
    "    # Get tokenized prompt for the specified seed\n",
    "    tokenized_prompt = get_prompt(seq_len, seed, print_prompt=False)\n",
    "    input_tokens = tokenized_prompt.to(model.cfg.device)\n",
    "    \n",
    "    # Get string tokens for the full sequence\n",
    "    str_tokens = model.to_str_tokens(input_tokens[0])\n",
    "    \n",
    "    # Find indices where \"Output:\" and \"Features:\" appear\n",
    "    output_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Output\"]\n",
    "    feature_indices = [i for i, token in enumerate(str_tokens[24:], start=24) if token == \"Feature\"]\n",
    "    \n",
    "    # Get positions of first number token after each marker\n",
    "    output_positions = []\n",
    "    for idx in output_indices:\n",
    "        current_pos = idx + 3  # Skip \"Output: \"\n",
    "        if current_pos < len(str_tokens) - 1:\n",
    "            output_positions.append(current_pos)\n",
    "    \n",
    "    feature_positions = []\n",
    "    for idx in feature_indices:\n",
    "        current_pos = idx + 5  # Skip \"Features n: \"\n",
    "        if current_pos < len(str_tokens) - 1:\n",
    "            feature_positions.append(current_pos)\n",
    "    \n",
    "    # Print results\n",
    "    if print_info:\n",
    "        print(\"\\nPositions of first number token after 'Output:':\")\n",
    "        print(f\"Positions: {output_positions}\")\n",
    "        \n",
    "        print(\"\\nPositions of first number token after 'Feature:':\")\n",
    "        print(f\"Positions: {feature_positions}\")\n",
    "        \n",
    "        # Print example tokens at these positions\n",
    "        print(\"\\nExample tokens at these positions:\")\n",
    "        print(\"After Output:\", [str_tokens[pos] for pos in output_positions])\n",
    "        print(\"After Features:\", [str_tokens[pos] for pos in feature_positions])\n",
    "    \n",
    "    return output_positions, feature_positions\n",
    "\n",
    "# Test with a single sequence length\n",
    "seq_len = 25\n",
    "output_pos, feature_pos = check_token_positions(model, dataset, seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0d820",
   "metadata": {},
   "source": [
    "Let's Look at the heads\n",
    "- Check for induction heads.\n",
    "- Check for heads which attend to the numbers after \"Features:\"\n",
    "- Check for heads which attend to numbers after \"Outputs:\"\n",
    "- Check for heads which attend to just the previous \"Features:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "seq_len = 25\n",
    "dataset = get_dataset_friedman_2\n",
    "random_int = 1\n",
    "tokenized_prompt = get_prompt(seq_len, random_int, print_prompt=False)\n",
    "output_pos, feature_pos = check_token_positions(model, dataset, seq_len, print_info=False)\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def imshow_multi(tensor, num_examples, xaxis=\"\", yaxis=\"\", title=\"Example Scores by Head\", renderer=None):\n",
    "    \"\"\"\n",
    "    Display multiple example scores by head in a grid of square plots, each with its own color scale.\n",
    "    \n",
    "    Args:\n",
    "        tensor: The tensor containing scores for each example.\n",
    "        num_examples: Number of examples to plot.\n",
    "        xaxis: Label for the x-axis.\n",
    "        yaxis: Label for the y-axis.\n",
    "        title: Title for the entire plot.\n",
    "        renderer: Optional renderer for displaying the plot.\n",
    "    \"\"\"\n",
    "    # Determine the number of rows and columns for the grid\n",
    "    num_cols = int(num_examples**0.5)\n",
    "    num_rows = (num_examples + num_cols - 1) // num_cols  # Ceiling division\n",
    "\n",
    "    # Create a subplot grid\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[f\"Example {i}\" for i in range(num_examples)])\n",
    "    \n",
    "    # Add each example's score as a subplot\n",
    "    for i in range(num_examples):\n",
    "        row = i // num_cols + 1\n",
    "        col = i % num_cols + 1\n",
    "        example_tensor = utils.to_numpy(tensor[..., i])\n",
    "        \n",
    "        # Determine the min and max for the color scale of this example\n",
    "        zmin = example_tensor.min()\n",
    "        zmax = example_tensor.max()\n",
    "        \n",
    "        heatmap = px.imshow(\n",
    "            example_tensor,\n",
    "            color_continuous_midpoint=0.0,  # Use the same midpoint\n",
    "            color_continuous_scale=\"RdBu\",  # Use the same color scale\n",
    "            labels={\"x\": xaxis, \"y\": yaxis},\n",
    "            zmin=zmin,\n",
    "            zmax=zmax\n",
    "        )\n",
    "        \n",
    "        # Add the heatmap to the subplot\n",
    "        for trace in heatmap.data:\n",
    "            fig.add_trace(trace, row=row, col=col)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(title_text=title, height=300 * num_rows, width=300 * num_cols)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show(renderer)\n",
    "\n",
    "induction_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "per_example_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads, len(output_pos)), device=model.cfg.device)\n",
    "per_example_accumulated_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads, len(output_pos)), device=model.cfg.device)\n",
    "all_examples_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "all_example_accumulated_score_store = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "\n",
    "def induction_score_hook(\n",
    "    pattern: Float[t.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "):\n",
    "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
    "    # (This only has entries for tokens with index>=seq_len)\n",
    "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
    "    # Get an average score per head\n",
    "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "    # Store the result.\n",
    "    induction_score_store[hook.layer(), :] = induction_score\n",
    "\n",
    "def accumulated_attention_hook(\n",
    "    pattern: Float[t.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "    output_positions,\n",
    "    feature_positions\n",
    "):\n",
    "    \"\"\"\n",
    "    Hook to measure accumulated attention from current output positions to all previous output and feature positions.\n",
    "    \n",
    "    Args:\n",
    "        pattern: Attention pattern tensor with shape [batch, head_index, dest_pos, source_pos]\n",
    "        hook: HookPoint object containing layer information\n",
    "        output_positions: List of positions of first number after \"Output:\"\n",
    "        feature_positions: List of positions of first numbers after \"Features:\"\n",
    "    \"\"\"\n",
    "    batch_size = pattern.shape[0]\n",
    "    n_heads = pattern.shape[1]\n",
    "    scores = []\n",
    "    \n",
    "    # For each output position\n",
    "    for i, output_pos in enumerate(output_positions):\n",
    "        # Get all previous output and feature positions\n",
    "        relevant_positions = [pos for pos in output_positions if pos < output_pos] + \\\n",
    "                             [pos for pos in feature_positions if pos < output_pos]\n",
    "        \n",
    "        # Get attention scores from current output position to all previous relevant positions\n",
    "        # Shape: [head_index, 1, source_pos]\n",
    "        output_attention = pattern[0, :, output_pos:output_pos+1, :]  # Using first batch element\n",
    "        \n",
    "        # Calculate mean attention to the relevant positions\n",
    "        # Shape: [head_index]\n",
    "        if relevant_positions:\n",
    "            accumulated_attention = output_attention[:, 0, relevant_positions].mean(dim=-1)\n",
    "            per_example_accumulated_score_store[hook.layer(), : , i] = accumulated_attention\n",
    "            scores.append(accumulated_attention)\n",
    "    \n",
    "    # Average across outputs\n",
    "    if scores:\n",
    "        example_score = t.stack(scores).mean(dim=0)\n",
    "        # Store the result in the global store\n",
    "        all_example_accumulated_score_store[hook.layer(), :] = example_score\n",
    "\n",
    "def all_example_hook(\n",
    "    pattern: Float[t.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: HookPoint,\n",
    "    output_positions,\n",
    "    feature_positions\n",
    "):\n",
    "    \"\"\"\n",
    "    Hook to measure attention from output positions to previous feature positions.\n",
    "    \n",
    "    Args:\n",
    "        pattern: Attention pattern tensor with shape [batch, head_index, dest_pos, source_pos]\n",
    "        hook: HookPoint object containing layer information\n",
    "        output_positions: List of positions of first number after \"Output:\"\n",
    "        feature_positions: List of positions of first numbers after \"Features:\"\n",
    "    \"\"\"\n",
    "    batch_size = pattern.shape[0]\n",
    "    n_heads = pattern.shape[1]\n",
    "    scores = []\n",
    "    \n",
    "    # For each output position\n",
    "    for i, output_pos in enumerate(output_positions):\n",
    "        # Get the 3 relevant feature positions that come before this output\n",
    "        relevant_feature_pos = [pos for pos in feature_positions if pos < output_pos][-3:]\n",
    "        \n",
    "        \n",
    "        # Get attention scores from output position to feature positions\n",
    "        # Shape: [head_index, 1, source_pos]\n",
    "        output_attention = pattern[0, :, output_pos:output_pos+1, :]  # Using first batch element\n",
    "        \n",
    "        # Calculate mean attention to the relevant feature positions\n",
    "        # Shape: [head_index]\n",
    "        feature_attention = output_attention[:, 0, relevant_feature_pos].mean(dim=-1)\n",
    "        per_example_score_store[hook.layer(), : , i] = feature_attention\n",
    "        scores.append(feature_attention)\n",
    "    \n",
    "    # Average across outputs\n",
    "    example_score = t.stack(scores).mean(dim=0)\n",
    "    \n",
    "    # Store the result in the global store\n",
    "    all_examples_score_store[hook.layer(), :] = example_score\n",
    "\n",
    "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
    "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
    "\n",
    "model.run_with_hooks(\n",
    "    tokenized_prompt, \n",
    "    return_type=None,  # For efficiency, we don't need to calculate the logits\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            pattern_hook_names_filter,\n",
    "            induction_score_hook\n",
    "        ),\n",
    "        (\n",
    "            pattern_hook_names_filter,\n",
    "            functools.partial(\n",
    "                all_example_hook,\n",
    "                output_positions=output_pos,  # Use positions for the first seed\n",
    "                feature_positions=feature_pos  # Use positions for the first seed\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            pattern_hook_names_filter,\n",
    "            functools.partial(\n",
    "                accumulated_attention_hook,\n",
    "                output_positions=output_pos,  # Use positions for the first seed\n",
    "                feature_positions=feature_pos  # Use positions for the first seed\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "imshow(induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head\")\n",
    "imshow(all_examples_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Per Example Score Avg by Head\")\n",
    "imshow(all_example_accumulated_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Accumulated Example Score Avg by Head\")\n",
    "imshow_multi(per_example_score_store, per_example_score_store.shape[-1], xaxis=\"Head\", yaxis=\"Layer\", title=\"Example Scores by Head\")\n",
    "imshow_multi(per_example_accumulated_score_store, per_example_accumulated_score_store.shape[-1], xaxis=\"Head\", yaxis=\"Layer\", title=\"Accumulated Example by Head\")\n",
    "\n",
    "for i in range(per_example_score_store.shape[-1]):\n",
    "    imshow(per_example_score_store[..., i], xaxis=\"Head\", yaxis=\"Layer\", title=f\"Example {i} Score by Head\")\n",
    "\n",
    "for i in range(per_example_accumulated_score_store.shape[-1]):\n",
    "    imshow(per_example_accumulated_score_store[..., i], xaxis=\"Head\", yaxis=\"Layer\", title=f\"Accumulated Example {i} Score by Head\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29499cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the number of seeds\n",
    "num_seeds = 100\n",
    "\n",
    "output_pos, feature_pos = check_token_positions(model, dataset, seq_len, print_info=False)\n",
    "\n",
    "\n",
    "# Initialize accumulators for scores\n",
    "induction_score_accumulator = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "all_examples_score_accumulator = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "all_example_accumulated_score_accumulator = t.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "per_example_score_store_accumulator = t.zeros((model.cfg.n_layers, model.cfg.n_heads, len(output_pos)), device=model.cfg.device)\n",
    "per_example_accumulated_score_store_accumulator = t.zeros((model.cfg.n_layers, model.cfg.n_heads, len(output_pos)), device=model.cfg.device)\n",
    "\n",
    "# Loop over seeds\n",
    "for seed in tqdm(range(num_seeds), desc=\"Running seeds\"):\n",
    "    # Get tokenized prompt for the current seed\n",
    "    tokenized_prompt = get_prompt(seq_len, seed, print_prompt=False)\n",
    "    output_pos, feature_pos = check_token_positions(model, dataset, seq_len, print_info=False)\n",
    "\n",
    "    # Run the model with hooks\n",
    "    model.run_with_hooks(\n",
    "        tokenized_prompt, \n",
    "        return_type=None,  # For efficiency, we don't need to calculate the logits\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                pattern_hook_names_filter,\n",
    "                induction_score_hook\n",
    "            ),\n",
    "            (\n",
    "                pattern_hook_names_filter,\n",
    "                functools.partial(\n",
    "                    all_example_hook,\n",
    "                    output_positions=output_pos,  # Use positions for the current seed\n",
    "                    feature_positions=feature_pos  # Use positions for the current seed\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                pattern_hook_names_filter,\n",
    "                functools.partial(\n",
    "                    accumulated_attention_hook,\n",
    "                    output_positions=output_pos,  # Use positions for the current seed\n",
    "                    feature_positions=feature_pos  # Use positions for the current seed\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Accumulate scores\n",
    "    induction_score_accumulator += induction_score_store\n",
    "    all_examples_score_accumulator += all_examples_score_store\n",
    "    all_example_accumulated_score_accumulator += all_example_accumulated_score_store\n",
    "    per_example_accumulated_score_store_accumulator += per_example_accumulated_score_store\n",
    "    per_example_score_store_accumulator += per_example_score_store\n",
    "\n",
    "# Average the scores\n",
    "induction_score_avg = induction_score_accumulator / num_seeds\n",
    "all_examples_score_avg = all_examples_score_accumulator / num_seeds\n",
    "all_example_accumulated_score_avg = all_example_accumulated_score_accumulator / num_seeds\n",
    "per_example_accumulated_score_store_avg = per_example_accumulated_score_store_accumulator / num_seeds\n",
    "per_example_score_store_avg = per_example_score_store_accumulator / num_seeds\n",
    "\n",
    "# Plot the averaged scores\n",
    "imshow(induction_score_avg, xaxis=\"Head\", yaxis=\"Layer\", title=\"Average Induction Score by Head\")\n",
    "imshow(all_examples_score_avg, xaxis=\"Head\", yaxis=\"Layer\", title=\"Average Per Example Score by Head\")\n",
    "imshow(all_example_accumulated_score_avg, xaxis=\"Head\", yaxis=\"Layer\", title=\"Average Accumulated Example Score by Head\")\n",
    "imshow_multi(per_example_score_store_avg, per_example_score_store_avg.shape[-1], xaxis=\"Head\", yaxis=\"Layer\", title=\"Example Scores by Head\")\n",
    "imshow_multi(per_example_accumulated_score_store_avg, per_example_accumulated_score_store_avg.shape[-1], xaxis=\"Head\", yaxis=\"Layer\", title=\"Accumulated Example by Head\")\n",
    "\n",
    "for i in range(per_example_score_store_avg.shape[-1]):\n",
    "    imshow(per_example_accumulated_score_store_avg[..., i], xaxis=\"Head\", yaxis=\"Layer\", title=f\"Accumulated Example {i} Score by Head\")\n",
    "\n",
    "for i in range(per_example_score_store_avg.shape[-1]):\n",
    "    imshow(per_example_accumulated_score_store_avg[..., i], xaxis=\"Head\", yaxis=\"Layer\", title=f\"Accumulated Example {i} Score by Head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def visualize_mlp_layers(model, input_tokens, num_last_layers=3):\n",
    "    \"\"\"\n",
    "    Visualize MLP activations for the last few layers using plotly with zero values in white\n",
    "    \"\"\"\n",
    "    mlp_activations = {}\n",
    "    \n",
    "    def mlp_hook(act, hook, layer_num):\n",
    "        if layer_num >= model.cfg.n_layers - num_last_layers:\n",
    "            mlp_activations[f'layer_{layer_num}'] = act.detach()\n",
    "        return act\n",
    "\n",
    "    # Create hooks for each layer\n",
    "    hooks = []\n",
    "    for layer_num in range(model.cfg.n_layers):\n",
    "        hooks.append((\n",
    "            f'blocks.{layer_num}.hook_mlp_in',\n",
    "            lambda act, hook, ln=layer_num: mlp_hook(act, hook, ln)\n",
    "        ))\n",
    "\n",
    "    # Run model with hooks\n",
    "    model.set_use_hook_mlp_in(True)\n",
    "    _ = model.run_with_hooks(\n",
    "        input_tokens,\n",
    "        fwd_hooks=hooks\n",
    "    )\n",
    "    \n",
    "    # Custom colorscale with white at zero\n",
    "    custom_colorscale = [\n",
    "        [0, 'blue'],        # Negative values\n",
    "        [0.5, 'white'],     # Zero\n",
    "        [1, 'red']          # Positive values\n",
    "    ]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=num_last_layers, \n",
    "        cols=1,\n",
    "        subplot_titles=[f'MLP Input Activations - Layer {layer_num}' \n",
    "                       for layer_num in range(model.cfg.n_layers - num_last_layers, model.cfg.n_layers)]\n",
    "    )\n",
    "    \n",
    "    # Add heatmaps to subplots\n",
    "    for idx, layer_num in enumerate(range(model.cfg.n_layers - num_last_layers, model.cfg.n_layers)):\n",
    "        layer_key = f'layer_{layer_num}'\n",
    "        if layer_key in mlp_activations:\n",
    "            acts = mlp_activations[layer_key].squeeze(0)  # Remove batch dimension\n",
    "            acts_np = acts.cpu().numpy()\n",
    "            max_abs_val = float(max(abs(acts.min()), abs(acts.max())))\n",
    "            \n",
    "            heatmap = go.Heatmap(\n",
    "                z=acts_np,\n",
    "                colorscale=custom_colorscale,\n",
    "                zmid=0,  # Set middle of color scale to zero\n",
    "                zmin=-max_abs_val,  # Symmetric color scale\n",
    "                zmax=max_abs_val,\n",
    "                showscale=True,\n",
    "                colorbar=dict(title='Activation Value')\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(heatmap, row=idx+1, col=1)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=400 * num_last_layers,\n",
    "        width=1000,\n",
    "        title_text=\"MLP Layer Activations\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    for i in range(num_last_layers):\n",
    "        fig.update_xaxes(title_text=\"Hidden Dimension\", row=i+1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Token Position\", row=i+1, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Create a custom prompt\n",
    "custom_prompt = \"\"\"Let's solve a math problem step by step:\n",
    "Input: Calculate 2 + 2\n",
    "Step 1: We start with the number 2\n",
    "Step 2: We add another 2\n",
    "Output: The result is 4\"\"\"\n",
    "\n",
    "# Convert prompt to tokens\n",
    "custom_tokens = model.to_tokens(custom_prompt)\n",
    "\n",
    "# Run visualizations with both prompts\n",
    "print(\"Visualizing original prompt:\")\n",
    "visualize_mlp_layers(model, tokenized_prompt, num_last_layers=3)\n",
    "# analyze_mlp_statistics(model, tokenized_prompt, num_last_layers=3)\n",
    "\n",
    "print(\"\\nVisualizing custom prompt:\")\n",
    "visualize_mlp_layers(model, custom_tokens, num_last_layers=3)\n",
    "# analyze_mlp_statistics(model, custom_tokens, num_last_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a640be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def analyze_significant_activations(model, input_tokens, num_last_layers=3, std_threshold=23):\n",
    "    \"\"\"\n",
    "    Analyze and list activations that are significantly above the mean (default: > 2 standard deviations)\n",
    "    \n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        input_tokens: Input tokens\n",
    "        num_last_layers: Number of last layers to analyze\n",
    "        std_threshold: Number of standard deviations above mean to consider significant\n",
    "    \"\"\"\n",
    "    mlp_activations = {}\n",
    "    \n",
    "    def mlp_hook(act, hook, layer_num):\n",
    "        if layer_num >= model.cfg.n_layers - num_last_layers:\n",
    "            mlp_activations[f'layer_{layer_num}'] = act.detach()\n",
    "        return act\n",
    "\n",
    "    # Create hooks for each layer\n",
    "    hooks = []\n",
    "    for layer_num in range(model.cfg.n_layers):\n",
    "        hooks.append((\n",
    "            f'blocks.{layer_num}.hook_mlp_in',\n",
    "            lambda act, hook, ln=layer_num: mlp_hook(act, hook, ln)\n",
    "        ))\n",
    "\n",
    "    # Run model with hooks\n",
    "    model.set_use_hook_mlp_in(True)\n",
    "    _ = model.run_with_hooks(\n",
    "        input_tokens,\n",
    "        fwd_hooks=hooks\n",
    "    )\n",
    "    \n",
    "    # Analyze each layer\n",
    "    for layer_num in range(model.cfg.n_layers - num_last_layers, model.cfg.n_layers):\n",
    "        layer_key = f'layer_{layer_num}'\n",
    "        if layer_key in mlp_activations:\n",
    "            acts = mlp_activations[layer_key].squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mean_act = acts.mean().item()\n",
    "            std_act = acts.std().item()\n",
    "            threshold = mean_act + (std_threshold * std_act)\n",
    "            \n",
    "            # Find significant activations\n",
    "            significant_mask = acts > threshold\n",
    "            if significant_mask.any():\n",
    "                print(f\"\\nLayer {layer_num} Significant Activations:\")\n",
    "                print(f\"Mean: {mean_act:.4f}, Std: {std_act:.4f}, Threshold: {threshold:.4f}\")\n",
    "                \n",
    "                # Get positions and values of significant activations\n",
    "                positions = t.nonzero(significant_mask)\n",
    "                for pos in positions:\n",
    "                    token_idx, hidden_idx = pos.tolist()\n",
    "                    value = acts[token_idx, hidden_idx].item()\n",
    "                    std_above_mean = (value - mean_act) / std_act\n",
    "                    \n",
    "                    # Get the actual token if possible\n",
    "                    token = input_tokens[0, token_idx].item()\n",
    "                    try:\n",
    "                        token_str = model.tokenizer.decode([token])\n",
    "                    except:\n",
    "                        token_str = f\"Token ID: {token}\"\n",
    "                    \n",
    "                    print(f\"Token: {token_str} (pos {token_idx}), \"\n",
    "                          f\"Hidden dim: {hidden_idx}, \"\n",
    "                          f\"Value: {value:.4f} \"\n",
    "                          f\"({std_above_mean:.2f} σ above mean)\")\n",
    "                \n",
    "                # Create visualization of significant activations\n",
    "                fig = go.Figure()\n",
    "                \n",
    "                # Add heatmap of only significant activations\n",
    "                significant_acts = acts.clone()\n",
    "                significant_acts[~significant_mask] = float('nan')\n",
    "                \n",
    "                heatmap = go.Heatmap(\n",
    "                    z=significant_acts.cpu().numpy(),\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title='Activation Value'),\n",
    "                    hoverongaps=False\n",
    "                )\n",
    "                \n",
    "                fig.add_trace(heatmap)\n",
    "                \n",
    "                fig.update_layout(\n",
    "                    title=f\"Layer {layer_num} Significant Activations (>{std_threshold}σ above mean)\",\n",
    "                    xaxis_title=\"Hidden Dimension\",\n",
    "                    yaxis_title=\"Token Position\",\n",
    "                    width=1000,\n",
    "                    height=400\n",
    "                )\n",
    "                \n",
    "                fig.show()\n",
    "\n",
    "# Example usage:\n",
    "analyze_significant_activations(model, tokenized_prompt, num_last_layers=3, std_threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mlp_for_specific_tokens(model, input_tokens, output_pos, feature_pos, num_last_layers=10):\n",
    "    \"\"\"\n",
    "    Analyze MLP activations specifically for output and feature number tokens\n",
    "    with zero values shown in white\n",
    "    \"\"\"\n",
    "    mlp_activations = {}\n",
    "    \n",
    "    def mlp_hook(act, hook, layer_num):\n",
    "        if layer_num >= model.cfg.n_layers - num_last_layers:\n",
    "            mlp_activations[f'layer_{layer_num}'] = act.detach()\n",
    "        return act\n",
    "\n",
    "    # Create hooks for each layer\n",
    "    hooks = []\n",
    "    for layer_num in range(model.cfg.n_layers):\n",
    "        hooks.append((\n",
    "            f'blocks.{layer_num}.hook_mlp_out',\n",
    "            lambda act, hook, ln=layer_num: mlp_hook(act, hook, ln)\n",
    "        ))\n",
    "\n",
    "    # Run model with hooks\n",
    "    model.set_use_hook_mlp_in(True)\n",
    "    _ = model.run_with_hooks(\n",
    "        input_tokens,\n",
    "        fwd_hooks=hooks\n",
    "    )\n",
    "    \n",
    "    # Custom colorscale with white at zero\n",
    "    custom_colorscale = [\n",
    "        [0, 'blue'],        # Negative values\n",
    "        [0.5, 'white'],     # Zero\n",
    "        [1, 'red']          # Positive values\n",
    "    ]\n",
    "    \n",
    "    for layer_num in range(model.cfg.n_layers - num_last_layers, model.cfg.n_layers):\n",
    "        layer_key = f'layer_{layer_num}'\n",
    "        if layer_key in mlp_activations:\n",
    "            acts = mlp_activations[layer_key].squeeze(0)\n",
    "            \n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=1,\n",
    "                subplot_titles=(\n",
    "                    f'Layer {layer_num} - Output Number Tokens',\n",
    "                    f'Layer {layer_num} - Feature Number Tokens'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Plot output token activations\n",
    "            output_acts = acts[output_pos, :]\n",
    "            output_acts_np = output_acts.cpu().numpy()\n",
    "            max_abs_val = float(max(abs(output_acts.min()), abs(output_acts.max())))  # Convert to float\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=output_acts_np,\n",
    "                    colorscale=custom_colorscale,\n",
    "                    zmid=0,  # Set middle of color scale to zero\n",
    "                    zmin=-max_abs_val,  # Symmetric color scale\n",
    "                    zmax=max_abs_val,\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title='Activation Value', y=0.85, len=0.35)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Plot feature token activations\n",
    "            feature_acts = acts[feature_pos, :]\n",
    "            feature_acts_np = feature_acts.cpu().numpy()\n",
    "            max_abs_val = float(max(abs(feature_acts.min()), abs(feature_acts.max())))  # Convert to float\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=feature_acts_np,\n",
    "                    colorscale=custom_colorscale,\n",
    "                    zmid=0,  # Set middle of color scale to zero\n",
    "                    zmin=-max_abs_val,  # Symmetric color scale\n",
    "                    zmax=max_abs_val,\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title='Activation Value', y=0.35, len=0.35)\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Update layout\n",
    "            fig.update_layout(\n",
    "                height=800,\n",
    "                width=1000,\n",
    "                title_text=f\"MLP Activations for Output and Feature Tokens - Layer {layer_num}\"\n",
    "            )\n",
    "            \n",
    "            # Update axes labels\n",
    "            fig.update_xaxes(title_text=\"Hidden Dimension\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Hidden Dimension\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"Token Index\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Token Index\", row=2, col=1)\n",
    "            \n",
    "            fig.show()\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"\\nLayer {layer_num} Statistics:\")\n",
    "            print(\"\\nOutput Token Statistics:\")\n",
    "            print(f\"Mean activation: {output_acts.mean():.4f}\")\n",
    "            print(f\"Std deviation: {output_acts.std():.4f}\")\n",
    "            print(f\"Max activation: {output_acts.max():.4f}\")\n",
    "            print(f\"Min activation: {output_acts.min():.4f}\")\n",
    "            print(f\"Sparsity: {(output_acts == 0).float().mean() * 100:.2f}%\")\n",
    "            \n",
    "            print(\"\\nFeature Token Statistics:\")\n",
    "            print(f\"Mean activation: {feature_acts.mean():.4f}\")\n",
    "            print(f\"Std deviation: {feature_acts.std():.4f}\")\n",
    "            print(f\"Max activation: {feature_acts.max():.4f}\")\n",
    "            print(f\"Min activation: {feature_acts.min():.4f}\")\n",
    "            print(f\"Sparsity: {(feature_acts == 0).float().mean() * 100:.2f}%\")\n",
    "\n",
    "# Get the positions and run the analysis\n",
    "output_pos, feature_pos = check_token_positions(model, dataset, seq_len, print_info=False)\n",
    "tok = model.to_tokens(\"HI MOM\")\n",
    "analyze_mlp_for_specific_tokens(model, tok, output_pos, feature_pos, num_last_layers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6f248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
